{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1eb99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "model_name = \"ovedrive/qwen-image-4bit\"\n",
    "\n",
    "# Set dtype depending on your GPU\n",
    "torch_dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the pipeline\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch_dtype\n",
    ").to(device)\n",
    "\n",
    "#prompt = (\"A scenic mountain landscape at sunset, ultra-detailed, cinematic style\")\n",
    "\n",
    "xprompt = '''Simple black and white line drawing of a two-lane road in Rwanda, straight path, tyre marks, \n",
    "bordered by grass, no cars — all in coloring page style: outlines only, no filled-in areas, no shading, \n",
    "no solid black, no color, minimal detail.'''\n",
    "\n",
    "image = pipe(\n",
    "    prompt=xprompt,\n",
    "    num_inference_steps=20,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    guidance_scale=7.5,\n",
    ").images[0]\n",
    "\n",
    "image.save(\"qwen_image_4bit_output.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e62c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5faf281d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b05d942f03546928ef801c621e072f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are loading your model in 8bit or 4bit but no linear modules were found in your model. Please double check your model architecture, or submit an issue on github if you think this is a bug.\n",
      "The config attributes {'pooled_projection_dim': 768} were passed to QwenImageTransformer2DModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7175efdab0144bba67628d340d645e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61d7df2c3c44372ab8ce41b21b8eb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478b4a02dcb846b4aff3278858034fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_name = \"ovedrive/qwen-image-4bit\"\n",
    "\n",
    "# Load the pipeline\n",
    "if torch.cuda.is_available():\n",
    "    torch_dtype = torch.bfloat16\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    torch_dtype = torch.float32\n",
    "    device = \"cpu\"\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch_dtype)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "positive_magic = {\"en\": \"Ultra HD, 4K, cinematic composition.\",  # for english prompt,\n",
    "    \"zh\": \"超清，4K，电影级构图\" # for chinese prompt,\n",
    "}\n",
    "\n",
    "# Generate image\n",
    "prompt = '''A coffee shop entrance features a chalkboard sign reading \"Qwen Coffee 😊 $2 per cup,\" \n",
    "with a neon light beside it displaying \"通义千问\". \n",
    "Next to it hangs a poster showing a beautiful Chinese woman, and beneath the poster is written \n",
    "\"π≈3.1415926-53589793-23846264-33832795-02384197\". Ultra HD, 4K, cinematic composition'''\n",
    "\n",
    "negative_prompt = \" \" # using an empty string if you do not have specific concept to remove\n",
    "\n",
    "\n",
    "# Generate with different aspect ratios\n",
    "aspect_ratios = {\n",
    "    \"1:1\": (1328, 1328),\n",
    "    \"16:9\": (1664, 928),\n",
    "    \"9:16\": (928, 1664),\n",
    "    \"4:3\": (1472, 1140),\n",
    "    \"3:4\": (1140, 1472),\n",
    "    \"3:2\": (1584, 1056),\n",
    "    \"2:3\": (1056, 1584),\n",
    "}\n",
    "\n",
    "width, height = aspect_ratios[\"16:9\"]\n",
    "\n",
    "image = pipe(\n",
    "    prompt=prompt + positive_magic[\"en\"],\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    num_inference_steps=20,\n",
    "    true_cfg_scale=4.0,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42)\n",
    ").images[0]\n",
    "\n",
    "image.save(\"example.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "565838de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8892393d0a4864b2236e9efec331cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xprompt = '''Black and white line drawing of a rural health centre in Rwanda, sign saying 'Health Centre', \n",
    "small building, Rwandan nurse outside — all in coloring page style: outlines only, no filled-in areas, \n",
    "no shading, no solid black, no color, simple and clear.'''\n",
    "\n",
    "\n",
    "image = pipe(\n",
    "    prompt=xprompt,\n",
    "    num_inference_steps=20,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    guidance_scale=7.5,\n",
    ").images[0]\n",
    "\n",
    "image.save(\"qwen_image_4bit_output_healthcenter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ea9c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa85e8f1c144eb5a72dcba807cde970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xprompt = '''Black and white line drawing of a rural health centre in Rwanda, sign saying 'Health Centre', \n",
    "small building, Rwandan nurse outside.'''\n",
    "\n",
    "\n",
    "image = pipe(\n",
    "    prompt=xprompt,\n",
    "    num_inference_steps=50,\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    guidance_scale=7.5,\n",
    ").images[0]\n",
    "\n",
    "image.save(\"qwen_image_4bit_output_healthcenter_3.png\")\n",
    "\n",
    "\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b334cf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce484832cb774109b4d3bb35e981cc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_magic = {\"en\": \"Ultra HD, 4K, cinematic composition.\",  # for english prompt,\n",
    "    \"zh\": \"超清，4K，电影级构图\" # for chinese prompt,\n",
    "}\n",
    "\n",
    "# Generate image\n",
    "prompt = '''A coffee shop entrance features a chalkboard sign reading \"Qwen Coffee 😊 $2 per cup,\" \n",
    "with a neon light beside it displaying \"Cafe Zen\". \n",
    "Next to it hangs a poster showing a beautiful African  woman , and beneath the poster is written \n",
    "\"Murakaza neza\". Ultra HD, 4K, cinematic composition'''\n",
    "\n",
    "negative_prompt = \" \" # using an empty string if you do not have specific concept to remove\n",
    "\n",
    "\n",
    "# Generate with different aspect ratios\n",
    "aspect_ratios = {\n",
    "    \"1:1\": (1328, 1328),\n",
    "    \"16:9\": (1664, 928),\n",
    "    \"9:16\": (928, 1664),\n",
    "    \"4:3\": (1472, 1140),\n",
    "    \"3:4\": (1140, 1472),\n",
    "    \"3:2\": (1584, 1056),\n",
    "    \"2:3\": (1056, 1584),\n",
    "}\n",
    "\n",
    "width, height = aspect_ratios[\"16:9\"]\n",
    "\n",
    "image = pipe(\n",
    "    prompt=prompt + positive_magic[\"en\"],\n",
    "    negative_prompt=negative_prompt,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    num_inference_steps=20,\n",
    "    true_cfg_scale=4.0,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(4)\n",
    ").images[0]\n",
    "\n",
    "image.save(\"example_3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385436af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23da0366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xDiffusers)",
   "language": "python",
   "name": "xdiffusers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
